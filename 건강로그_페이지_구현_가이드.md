# 🏥 LifeBit 건강로그 페이지 구현 가이드

## 📋 목차
1. [개요 및 목표](#개요-및-목표)
2. [기술 아키텍처](#기술-아키텍처)
3. [데이터 파이프라인 설계](#데이터-파이프라인-설계)
4. [프론트엔드 구현 계획](#프론트엔드-구현-계획)
5. [백엔드 API 설계](#백엔드-api-설계)
6. [실시간 데이터 처리](#실시간-데이터-처리)
7. [머신러닝 추천 시스템](#머신러닝-추천-시스템)
8. [Airflow 파이프라인](#airflow-파이프라인)
9. [구현 단계별 계획](#구현-단계별-계획)
10. [테스트 및 배포](#테스트-및-배포)

---

## 🎯 개요 및 목표

### 페이지 목적
- 사용자 건강 데이터의 **실시간 시각화**
- **머신러닝 기반 개인화 추천** 제공
- **Airflow 파이프라인**을 통한 자동화된 데이터 처리
- 사용자 건강 목표 달성률 추적

### 핵심 기능
1. **실시간 건강 데이터 대시보드**
2. **AI 기반 운동/식단 추천**
3. **자동화된 데이터 분석 및 통계**
4. **목표 달성률 시각화**

---

## 🏗️ 기술 아키텍처

### 전체 시스템 구조
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Frontend      │    │   Backend       │    │   Database      │
│   (React/Vite)  │◄──►│   (FastAPI)     │◄──►│   (Supabase)    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Real-time     │    │   ML Model      │    │   Airflow       │
│   Updates       │    │   (Scikit-learn)│    │   Pipeline      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 기술 스택 상세
```typescript
// 프론트엔드
- React 18 + TypeScript
- Vite (빌드 도구)
- Tailwind CSS (스타일링)
- Recharts (차트 라이브러리)
- React Query (데이터 페칭)
- Zustand (상태 관리)

// 백엔드
- FastAPI (API 서버)
- SQLAlchemy (ORM)
- Pydantic (데이터 검증)
- PyJWT (인증)

// 데이터베이스
- Supabase (PostgreSQL + 실시간 기능)
- Redis (캐싱)

// 머신러닝
- Scikit-learn (추천 모델)
- Pandas (데이터 처리)
- NumPy (수치 계산)

// 데이터 파이프라인
- Apache Airflow (워크플로우 자동화)
- Python (데이터 처리 스크립트)
```

---

## 🔄 데이터 파이프라인 설계

### 실시간 데이터 플로우
```mermaid
graph TD
    A[사용자 데이터 입력] --> B[Supabase 실시간 저장]
    B --> C[Airflow 트리거]
    C --> D[데이터 전처리]
    D --> E[ML 모델 업데이트]
    E --> F[추천 결과 생성]
    F --> G[Redis 캐시 저장]
    G --> H[프론트엔드 실시간 반영]
```

### 데이터 처리 단계
```python
# 1. 데이터 수집
user_input → Supabase → 실시간 저장

# 2. 데이터 전처리 (Airflow)
raw_data → 정제 → 정규화 → 특성 추출

# 3. ML 모델 학습
processed_data → 모델 학습 → 성능 평가 → 모델 저장

# 4. 추천 생성
user_profile + 모델 → 추천 결과 → 캐시 저장

# 5. 실시간 전달
캐시 → WebSocket → 프론트엔드
```

---

## 🎨 프론트엔드 구현 계획

### 1. API 통합 관리 (api.tsx)
```typescript
// apps/frontend-vite/src/api/healthApi.tsx
import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';
import { supabase } from '../lib/supabase';

// API 엔드포인트 타입 정의
interface HealthApiEndpoints {
  // 건강 기록 관련
  getHealthRecords: (userId: string, period: string) => Promise<HealthRecord[]>;
  createHealthRecord: (data: CreateHealthRecordData) => Promise<HealthRecord>;
  
  // 목표 관련
  getUserGoals: (userId: string) => Promise<UserGoal>;
  updateUserGoals: (userId: string, data: UpdateGoalData) => Promise<UserGoal>;
  
  // 운동 기록 관련
  getExerciseSessions: (userId: string, period: string) => Promise<ExerciseSession[]>;
  createExerciseSession: (data: CreateExerciseData) => Promise<ExerciseSession>;
  
  // 식단 기록 관련
  getMealLogs: (userId: string, period: string) => Promise<MealLog[]>;
  createMealLog: (data: CreateMealData) => Promise<MealLog>;
  
  // 통계 관련
  getHealthStatistics: (userId: string, period: string) => Promise<HealthStatistics>;
  
  // 추천 관련
  getRecommendations: (userId: string) => Promise<Recommendation[]>;
  submitFeedback: (recommendationId: string, feedback: FeedbackData) => Promise<void>;
  
  // 실시간 구독
  subscribeToHealthUpdates: (userId: string, callback: (data: any) => void) => void;
}

// React Query 훅들
export const useHealthRecords = (userId: string, period: string) => {
  return useQuery({
    queryKey: ['healthRecords', userId, period],
    queryFn: () => healthApi.getHealthRecords(userId, period),
    staleTime: 5 * 60 * 1000, // 5분
  });
};

export const useUserGoals = (userId: string) => {
  return useQuery({
    queryKey: ['userGoals', userId],
    queryFn: () => healthApi.getUserGoals(userId),
    staleTime: 10 * 60 * 1000, // 10분
  });
};

export const useRecommendations = (userId: string) => {
  return useQuery({
    queryKey: ['recommendations', userId],
    queryFn: () => healthApi.getRecommendations(userId),
    staleTime: 30 * 60 * 1000, // 30분
  });
};

// 실시간 구독 훅
export const useHealthRealtime = (userId: string) => {
  const queryClient = useQueryClient();
  
  useEffect(() => {
    const subscription = healthApi.subscribeToHealthUpdates(userId, (data) => {
      // 실시간 데이터 업데이트 시 쿼리 무효화
      queryClient.invalidateQueries(['healthRecords', userId]);
      queryClient.invalidateQueries(['userGoals', userId]);
      queryClient.invalidateQueries(['recommendations', userId]);
    });
    
    return () => subscription.unsubscribe();
  }, [userId, queryClient]);
};
```

### 2. 페이지 컴포넌트 구조
```typescript
// apps/frontend-vite/src/pages/HealthLog.tsx
import React from 'react';
import { HealthDashboard } from '../components/health/HealthDashboard';
import { RecommendationPanel } from '../components/health/RecommendationPanel';
import { StatisticsCharts } from '../components/health/StatisticsCharts';
import { GoalProgress } from '../components/health/GoalProgress';

const HealthLog: React.FC = () => {
  const { user } = useAuth(); // 인증 훅
  
  return (
    <div className="min-h-screen bg-gray-50">
      <div className="container mx-auto px-4 py-8">
        {/* 헤더 */}
        <div className="mb-8">
          <h1 className="text-3xl font-bold text-gray-900">건강 로그</h1>
          <p className="text-gray-600 mt-2">실시간 건강 데이터와 AI 추천을 확인하세요</p>
        </div>
        
        {/* 메인 대시보드 */}
        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
          {/* 왼쪽: 통계 차트 */}
          <div className="lg:col-span-2">
            <StatisticsCharts userId={user.id} />
          </div>
          
          {/* 오른쪽: 추천 패널 */}
          <div className="lg:col-span-1">
            <RecommendationPanel userId={user.id} />
          </div>
        </div>
        
        {/* 하단: 목표 진행률 */}
        <div className="mt-8">
          <GoalProgress userId={user.id} />
        </div>
      </div>
    </div>
  );
};

export default HealthLog;
```

### 3. 차트 컴포넌트들
```typescript
// apps/frontend-vite/src/components/health/StatisticsCharts.tsx
import React from 'react';
import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer } from 'recharts';
import { useHealthRecords } from '../../api/healthApi';

interface StatisticsChartsProps {
  userId: string;
}

export const StatisticsCharts: React.FC<StatisticsChartsProps> = ({ userId }) => {
  const { data: healthRecords, isLoading } = useHealthRecords(userId, 'month');
  
  if (isLoading) {
    return <div className="animate-pulse">로딩 중...</div>;
  }
  
  return (
    <div className="bg-white rounded-lg shadow-md p-6">
      <h2 className="text-xl font-semibold mb-4">건강 지표 추이</h2>
      
      {/* 체중 변화 차트 */}
      <div className="mb-6">
        <h3 className="text-lg font-medium mb-3">체중 변화</h3>
        <ResponsiveContainer width="100%" height={300}>
          <LineChart data={healthRecords}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey="record_date" />
            <YAxis />
            <Tooltip />
            <Line type="monotone" dataKey="weight" stroke="#8884d8" />
          </LineChart>
        </ResponsiveContainer>
      </div>
      
      {/* BMI 변화 차트 */}
      <div>
        <h3 className="text-lg font-medium mb-3">BMI 변화</h3>
        <ResponsiveContainer width="100%" height={300}>
          <LineChart data={healthRecords}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey="record_date" />
            <YAxis />
            <Tooltip />
            <Line type="monotone" dataKey="bmi" stroke="#82ca9d" />
          </LineChart>
        </ResponsiveContainer>
      </div>
    </div>
  );
};
```

---

## 🔧 백엔드 API 설계

### 1. FastAPI 엔드포인트 구조
```python
# apps/ai-api-fastapi/main.py
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List, Optional
import redis
import json

app = FastAPI(title="LifeBit Health API", version="1.0.0")

# CORS 설정
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Redis 연결 (캐싱용)
redis_client = redis.Redis(host='localhost', port=6379, db=0)

# 건강 기록 관련 엔드포인트
@app.get("/api/health-records/{user_id}")
async def get_health_records(
    user_id: int, 
    period: str = "month",
    db: Session = Depends(get_db)
):
    """사용자 건강 기록 조회"""
    cache_key = f"health_records:{user_id}:{period}"
    
    # 캐시 확인
    cached_data = redis_client.get(cache_key)
    if cached_data:
        return json.loads(cached_data)
    
    # 데이터베이스 조회
    records = db.query(HealthRecord).filter(
        HealthRecord.user_id == user_id
    ).order_by(HealthRecord.record_date.desc()).all()
    
    # 캐시 저장
    redis_client.setex(cache_key, 300, json.dumps(records))  # 5분 캐시
    
    return records

@app.post("/api/health-records")
async def create_health_record(
    record: CreateHealthRecordRequest,
    db: Session = Depends(get_db)
):
    """건강 기록 생성"""
    db_record = HealthRecord(**record.dict())
    db.add(db_record)
    db.commit()
    db.refresh(db_record)
    
    # 실시간 업데이트를 위한 이벤트 발행
    await publish_health_update(db_record.user_id, "health_record_created")
    
    return db_record

# 추천 관련 엔드포인트
@app.get("/api/recommendations/{user_id}")
async def get_recommendations(user_id: int):
    """사용자 맞춤 추천 조회"""
    cache_key = f"recommendations:{user_id}"
    
    # 캐시 확인
    cached_data = redis_client.get(cache_key)
    if cached_data:
        return json.loads(cached_data)
    
    # ML 모델에서 추천 생성
    recommendations = await generate_recommendations(user_id)
    
    # 캐시 저장
    redis_client.setex(cache_key, 1800, json.dumps(recommendations))  # 30분 캐시
    
    return recommendations

# 통계 관련 엔드포인트
@app.get("/api/health-statistics/{user_id}")
async def get_health_statistics(
    user_id: int, 
    period: str = "month",
    db: Session = Depends(get_db)
):
    """건강 통계 조회"""
    cache_key = f"health_stats:{user_id}:{period}"
    
    cached_data = redis_client.get(cache_key)
    if cached_data:
        return json.loads(cached_data)
    
    # 통계 계산
    stats = await calculate_health_statistics(user_id, period, db)
    
    # 캐시 저장
    redis_client.setex(cache_key, 600, json.dumps(stats))  # 10분 캐시
    
    return stats
```

### 2. 데이터 모델 정의
```python
# apps/ai-api-fastapi/models.py
from sqlalchemy import Column, Integer, String, Float, Date, DateTime, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid

Base = declarative_base()

class HealthRecord(Base):
    __tablename__ = "health_records"
    
    health_record_id = Column(Integer, primary_key=True, index=True)
    uuid = Column(String, unique=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(Integer, ForeignKey("users.user_id"))
    weight = Column(Float)
    bmi = Column(Float)
    record_date = Column(Date, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)

class UserGoal(Base):
    __tablename__ = "user_goals"
    
    user_goal_id = Column(Integer, primary_key=True, index=True)
    uuid = Column(String, unique=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(Integer, ForeignKey("users.user_id"))
    weekly_workout_target = Column(Integer, default=3)
    daily_carbs_target = Column(Integer, default=200)
    daily_protein_target = Column(Integer, default=120)
    daily_fat_target = Column(Integer, default=60)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
```

---

## ⚡ 실시간 데이터 처리

### 1. Supabase 실시간 구독
```typescript
// apps/frontend-vite/src/lib/supabase.ts
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;
const supabaseKey = import.meta.env.VITE_SUPABASE_ANON_KEY;

export const supabase = createClient(supabaseUrl, supabaseKey);

// 실시간 구독 설정
export const subscribeToHealthUpdates = (userId: string, callback: (data: any) => void) => {
  const subscription = supabase
    .channel('health_updates')
    .on(
      'postgres_changes',
      {
        event: '*',
        schema: 'public',
        table: 'health_records',
        filter: `user_id=eq.${userId}`
      },
      (payload) => {
        callback(payload);
      }
    )
    .on(
      'postgres_changes',
      {
        event: '*',
        schema: 'public',
        table: 'user_goals',
        filter: `user_id=eq.${userId}`
      },
      (payload) => {
        callback(payload);
      }
    )
    .subscribe();

  return subscription;
};
```

### 2. WebSocket 실시간 업데이트
```python
# apps/ai-api-fastapi/websocket.py
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict
import json

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[int, WebSocket] = {}

    async def connect(self, websocket: WebSocket, user_id: int):
        await websocket.accept()
        self.active_connections[user_id] = websocket

    def disconnect(self, user_id: int):
        if user_id in self.active_connections:
            del self.active_connections[user_id]

    async def send_personal_message(self, message: str, user_id: int):
        if user_id in self.active_connections:
            await self.active_connections[user_id].send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections.values():
            await connection.send_text(message)

manager = ConnectionManager()

@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: int):
    await manager.connect(websocket, user_id)
    try:
        while True:
            data = await websocket.receive_text()
            # 메시지 처리
    except WebSocketDisconnect:
        manager.disconnect(user_id)
```

---

## 🤖 머신러닝 추천 시스템

### 1. 추천 모델 설계
```python
# apps/ai-api-fastapi/ml/recommendation_model.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib
import os

class HealthRecommendationModel:
    def __init__(self):
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.scaler = StandardScaler()
        self.model_path = "models/health_recommendation_model.pkl"
        self.scaler_path = "models/health_scaler.pkl"
        
    def prepare_features(self, user_data: dict) -> np.ndarray:
        """사용자 데이터를 특성 벡터로 변환"""
        features = [
            user_data.get('age', 30),
            user_data.get('weight', 70),
            user_data.get('height', 170),
            user_data.get('weekly_workout_target', 3),
            user_data.get('daily_carbs_target', 200),
            user_data.get('daily_protein_target', 120),
            user_data.get('daily_fat_target', 60),
            user_data.get('streak_days', 0),
            user_data.get('total_score', 0)
        ]
        return np.array(features).reshape(1, -1)
    
    def train(self, training_data: pd.DataFrame):
        """모델 학습"""
        X = training_data.drop(['target'], axis=1)
        y = training_data['target']
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # 특성 스케일링
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # 모델 학습
        self.model.fit(X_train_scaled, y_train)
        
        # 모델 저장
        self.save_model()
        
        return self.model.score(X_test_scaled, y_test)
    
    def predict(self, user_data: dict) -> dict:
        """사용자 맞춤 추천 생성"""
        features = self.prepare_features(user_data)
        features_scaled = self.scaler.transform(features)
        
        prediction = self.model.predict(features_scaled)[0]
        
        # 추천 로직
        recommendations = self.generate_recommendations(user_data, prediction)
        
        return recommendations
    
    def generate_recommendations(self, user_data: dict, prediction: float) -> dict:
        """추천 결과 생성"""
        recommendations = {
            'exercise_recommendations': [],
            'nutrition_recommendations': [],
            'health_tips': []
        }
        
        # 운동 추천
        if user_data.get('weekly_workout_target', 0) < 3:
            recommendations['exercise_recommendations'].append({
                'type': 'cardio',
                'duration': 30,
                'intensity': 'moderate',
                'reason': '주간 운동 목표 달성을 위한 유산소 운동'
            })
        
        # 영양 추천
        if user_data.get('daily_protein_target', 0) < 100:
            recommendations['nutrition_recommendations'].append({
                'type': 'protein',
                'food': '닭가슴살',
                'amount': '150g',
                'reason': '단백질 섭취 목표 달성을 위한 추천'
            })
        
        # 건강 팁
        recommendations['health_tips'].append({
            'tip': '충분한 수면을 취하세요',
            'priority': 'high'
        })
        
        return recommendations
    
    def save_model(self):
        """모델 저장"""
        os.makedirs('models', exist_ok=True)
        joblib.dump(self.model, self.model_path)
        joblib.dump(self.scaler, self.scaler_path)
    
    def load_model(self):
        """모델 로드"""
        if os.path.exists(self.model_path):
            self.model = joblib.load(self.model_path)
            self.scaler = joblib.load(self.scaler_path)
            return True
        return False
```

### 2. 추천 API 엔드포인트
```python
# apps/ai-api-fastapi/main.py
from ml.recommendation_model import HealthRecommendationModel

recommendation_model = HealthRecommendationModel()

@app.get("/api/recommendations/{user_id}")
async def get_recommendations(user_id: int, db: Session = Depends(get_db)):
    """사용자 맞춤 추천 조회"""
    
    # 사용자 데이터 조회
    user = db.query(User).filter(User.user_id == user_id).first()
    user_goals = db.query(UserGoal).filter(UserGoal.user_id == user_id).first()
    user_rankings = db.query(UserRanking).filter(UserRanking.user_id == user_id).first()
    
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    # 사용자 데이터 준비
    user_data = {
        'age': user.age,
        'weight': user.weight,
        'height': user.height,
        'weekly_workout_target': user_goals.weekly_workout_target if user_goals else 3,
        'daily_carbs_target': user_goals.daily_carbs_target if user_goals else 200,
        'daily_protein_target': user_goals.daily_protein_target if user_goals else 120,
        'daily_fat_target': user_goals.daily_fat_target if user_goals else 60,
        'streak_days': user_rankings.streak_days if user_rankings else 0,
        'total_score': user_rankings.total_score if user_rankings else 0
    }
    
    # 추천 생성
    recommendations = recommendation_model.predict(user_data)
    
    # 추천 결과 저장
    recommendation_record = Recommendation(
        user_id=user_id,
        recommendation_data=recommendations
    )
    db.add(recommendation_record)
    db.commit()
    
    return recommendations
```

---

## 🔄 Airflow 파이프라인

### 1. DAG 구조 설계
```python
# dags/health_data_pipeline.py
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.bash_operator import BashOperator
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import logging

default_args = {
    'owner': 'lifebit',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'health_data_pipeline',
    default_args=default_args,
    description='LifeBit 건강 데이터 처리 파이프라인',
    schedule_interval='0 */6 * * *',  # 6시간마다 실행
    catchup=False
)

def extract_health_data(**context):
    """건강 데이터 추출"""
    logging.info("건강 데이터 추출 시작")
    
    # Supabase에서 데이터 추출
    engine = create_engine('postgresql://user:password@localhost/lifebit_db')
    
    # 최근 24시간 데이터 추출
    query = """
    SELECT 
        hr.*, ug.weekly_workout_target, ug.daily_carbs_target,
        ug.daily_protein_target, ug.daily_fat_target
    FROM health_records hr
    LEFT JOIN user_goals ug ON hr.user_id = ug.user_id
    WHERE hr.created_at >= NOW() - INTERVAL '24 hours'
    """
    
    df = pd.read_sql(query, engine)
    
    # 데이터를 XCom에 저장
    context['task_instance'].xcom_push(key='health_data', value=df.to_dict())
    
    logging.info(f"추출된 데이터: {len(df)} 건")
    return len(df)

def transform_health_data(**context):
    """건강 데이터 변환 및 전처리"""
    logging.info("건강 데이터 변환 시작")
    
    # XCom에서 데이터 가져오기
    data_dict = context['task_instance'].xcom_pull(task_ids='extract_health_data', key='health_data')
    df = pd.DataFrame(data_dict)
    
    # 데이터 정제
    df = df.dropna(subset=['weight', 'bmi'])
    df['bmi_category'] = pd.cut(df['bmi'], 
                               bins=[0, 18.5, 25, 30, 100], 
                               labels=['저체중', '정상', '과체중', '비만'])
    
    # 특성 엔지니어링
    df['weight_change'] = df.groupby('user_id')['weight'].diff()
    df['bmi_change'] = df.groupby('user_id')['bmi'].diff()
    
    # 변환된 데이터 저장
    context['task_instance'].xcom_push(key='transformed_data', value=df.to_dict())
    
    logging.info(f"변환된 데이터: {len(df)} 건")
    return len(df)

def train_ml_model(**context):
    """머신러닝 모델 학습"""
    logging.info("ML 모델 학습 시작")
    
    # 변환된 데이터 가져오기
    data_dict = context['task_instance'].xcom_pull(task_ids='transform_health_data', key='transformed_data')
    df = pd.DataFrame(data_dict)
    
    if len(df) < 10:
        logging.warning("학습 데이터가 부족합니다")
        return 0
    
    # 모델 학습 (간단한 예시)
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    
    # 특성 선택
    features = ['weight', 'bmi', 'weekly_workout_target', 'daily_carbs_target']
    X = df[features].dropna()
    y = df.loc[X.index, 'bmi']  # BMI 예측
    
    if len(X) < 5:
        logging.warning("학습 가능한 데이터가 부족합니다")
        return 0
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = RandomForestRegressor(n_estimators=50, random_state=42)
    model.fit(X_train, y_train)
    
    # 모델 성능 평가
    score = model.score(X_test, y_test)
    logging.info(f"모델 성능 점수: {score:.3f}")
    
    # 모델 저장
    import joblib
    joblib.dump(model, '/tmp/health_model.pkl')
    
    return score

def update_recommendations(**context):
    """추천 결과 업데이트"""
    logging.info("추천 결과 업데이트 시작")
    
    # 모델 로드
    import joblib
    model = joblib.load('/tmp/health_model.pkl')
    
    # 사용자별 추천 생성
    engine = create_engine('postgresql://user:password@localhost/lifebit_db')
    
    # 활성 사용자 조회
    users_query = "SELECT user_id FROM users WHERE created_at >= NOW() - INTERVAL '30 days'"
    users_df = pd.read_sql(users_query, engine)
    
    recommendations = []
    for user_id in users_df['user_id']:
        # 사용자 데이터 조회
        user_data_query = f"""
        SELECT 
            u.age, u.weight, u.height,
            ug.weekly_workout_target, ug.daily_carbs_target
        FROM users u
        LEFT JOIN user_goals ug ON u.user_id = ug.user_id
        WHERE u.user_id = {user_id}
        """
        user_data = pd.read_sql(user_data_query, engine)
        
        if not user_data.empty and not user_data.isna().any().any():
            # 추천 생성
            features = user_data[['weight', 'height', 'weekly_workout_target', 'daily_carbs_target']].values
            prediction = model.predict(features)[0]
            
            recommendation = {
                'user_id': user_id,
                'recommendation_data': {
                    'predicted_bmi': float(prediction),
                    'exercise_tip': '주 3회 이상 운동을 권장합니다' if user_data['weekly_workout_target'].iloc[0] < 3 else '좋은 운동 습관을 유지하세요',
                    'nutrition_tip': '균형 잡힌 식단을 섭취하세요'
                }
            }
            recommendations.append(recommendation)
    
    # 추천 결과 저장
    if recommendations:
        recommendations_df = pd.DataFrame(recommendations)
        recommendations_df.to_sql('recommendation', engine, if_exists='append', index=False)
    
    logging.info(f"업데이트된 추천: {len(recommendations)} 건")
    return len(recommendations)

# 태스크 정의
extract_task = PythonOperator(
    task_id='extract_health_data',
    python_callable=extract_health_data,
    dag=dag
)

transform_task = PythonOperator(
    task_id='transform_health_data',
    python_callable=transform_health_data,
    dag=dag
)

train_task = PythonOperator(
    task_id='train_ml_model',
    python_callable=train_ml_model,
    dag=dag
)

update_task = PythonOperator(
    task_id='update_recommendations',
    python_callable=update_recommendations,
    dag=dag
)

# 태스크 순서 정의
extract_task >> transform_task >> train_task >> update_task
```

### 2. Airflow 설정
```yaml
# docker-compose.yml에 Airflow 추가
version: '3.8'
services:
  # 기존 서비스들...
  
  airflow-webserver:
    image: apache/airflow:2.7.1
    depends_on:
      - postgres-db
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-db/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    image: apache/airflow:2.7.1
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-db/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: scheduler
```

---

## 📋 구현 단계별 계획

### 1단계: 기본 인프라 구축 (1-2일)
```bash
# 1. Supabase 설정
- 프로젝트 생성
- 데이터베이스 연결 설정
- 실시간 기능 활성화

# 2. Airflow 설정
- Docker Compose에 Airflow 추가
- DAG 파일 작성
- 스케줄러 설정

# 3. Redis 설정
- 캐싱 서버 구축
- 연결 설정
```

### 2단계: 백엔드 API 개발 (2-3일)
```bash
# 1. FastAPI 엔드포인트 구현
- 건강 기록 CRUD
- 통계 계산 API
- 추천 API

# 2. 데이터베이스 모델 구현
- SQLAlchemy 모델 정의
- 마이그레이션 스크립트

# 3. 실시간 기능 구현
- WebSocket 연결
- Supabase 실시간 구독
```

### 3단계: 머신러닝 모델 개발 (2-3일)
```bash
# 1. 데이터 전처리
- 특성 엔지니어링
- 데이터 정제

# 2. 모델 학습
- 추천 알고리즘 구현
- 성능 평가

# 3. 모델 배포
- 모델 저장/로드
- API 연동
```

### 4단계: 프론트엔드 개발 (3-4일)
```bash
# 1. API 통합
- healthApi.tsx 구현
- React Query 설정

# 2. 차트 컴포넌트
- Recharts 설정
- 차트 컴포넌트 구현

# 3. 실시간 업데이트
- WebSocket 연결
- 실시간 데이터 반영
```

### 5단계: 통합 및 테스트 (1-2일)
```bash
# 1. 전체 시스템 통합
- 모든 컴포넌트 연결
- 에러 처리

# 2. 성능 최적화
- 캐싱 최적화
- 로딩 성능 개선

# 3. 테스트
- 단위 테스트
- 통합 테스트
```

---

## 🧪 테스트 및 배포

### 1. 테스트 전략
```typescript
// 단위 테스트
- API 엔드포인트 테스트
- 컴포넌트 테스트
- 모델 성능 테스트

// 통합 테스트
- 전체 워크플로우 테스트
- 실시간 데이터 동기화 테스트

// 성능 테스트
- 로딩 시간 측정
- 메모리 사용량 모니터링
```

### 2. 배포 체크리스트
```bash
# 환경 변수 설정
- Supabase 연결 정보
- Redis 연결 정보
- Airflow 설정

# 보안 설정
- API 키 관리
- CORS 설정
- 인증 토큰 관리

# 모니터링 설정
- 로그 수집
- 성능 모니터링
- 에러 추적
```

---

## 📞 추가 참고사항

### 개발 시 주의사항
1. **실시간 데이터 동기화**: Supabase 실시간 기능과 WebSocket을 적절히 조합
2. **캐싱 전략**: Redis를 활용한 효율적인 캐싱 구현
3. **에러 처리**: 네트워크 오류, 데이터 유효성 검증 등 철저한 에러 처리
4. **성능 최적화**: 대용량 데이터 처리 시 페이지네이션, 가상화 등 고려

### 확장 가능성
1. **추가 차트 타입**: 히트맵, 산점도, 박스플롯 등
2. **고급 분석**: 시계열 분석, 이상치 탐지 등
3. **개인화**: 사용자별 대시보드 커스터마이징
4. **모바일 최적화**: 반응형 디자인 및 터치 인터랙션

**마지막 업데이트:** 2024년 12월 19일  
**작성자:** 개발팀  
**버전:** 1.0 